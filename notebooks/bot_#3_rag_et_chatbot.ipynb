{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVDj1IfxaQmL"
      },
      "source": [
        "# Chatbot et RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOzlTqN9ahh6"
      },
      "source": [
        "üéØ L'objectif de ce notebook est de cr√©er un chatbot bas√© sur du RAG \"simple\".Les documents vectoris√©s sont en effet de type pdf, sans images ni tableau, et n'int√®gre aucun sommaire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apfGiMAVbIF6"
      },
      "source": [
        "## 1- Documents loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221k4cwxkXDR"
      },
      "source": [
        "Cette premi√®re √©tape consiste √† constituer une base documentaire sur laquelle entrainer notre mod√®le d'IA.\n",
        "Dans le cas pr√©sent, nous avons utilis√© un extrait du rapport climat 2024 sur la construction bas carbone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "W8J9cAxYlLAi",
        "outputId": "5f4e6bcf-54f3-4a3d-e119-020caa346055"
      },
      "outputs": [],
      "source": [
        "# on installe les packages n√©cessaires (outils) au projet\n",
        "\n",
        "!pip install pypdf\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GfvNy6bmacZr",
        "outputId": "ce4a7b77-c7fc-44fc-bf22-5c2d1b1065b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Conception et construction bas carbone Mat√©riaux bas carbone Le bois, solution de \n",
            "stockage carbone dans les constructions Les solutions pr√©fabriqu√©es de Savare, filiale \n",
            "sp√©cialis√©e dans la construction bois, sont d√©ploy√©es dans plusieurs projets en cours, \n",
            "comme le nouveau b√¢timent tertiaire du CHU de Rennes (Ille-et-Vilaine). In‚ÄôCube, le centre \n",
            "de recherche et d‚Äôinnovation de Danone, tr√®s ambitieux du fait de ses innovations \n",
            "environnementales, a √©t√© inaugur√© √† Gif-sur-Yvette (Essonne) en 2023. Eiffage Construction \n",
            "a eu no- ___ _La branche Construction a mis en place en 2023 une action intitul√©e ¬´ une \n",
            "variante bas carbone par offre d√©pos√©e ¬ª pour les appels d‚Äôoffres sup√©rieurs √† 5 millions \n",
            "d‚Äôeuros. Les variantes bas carbone seront syst√©matis√©es dans toutes les offres d√®s cette \n",
            "ann√©e. tamment recours au bois, utilis√© en √©l√©ment structurel et dans l‚Äôassemblage des \n",
            "planchers. Compact, √©quip√© de stores ext√©rieurs et de panneaux photovolta√Øques, r√©alis√© \n",
            "avec 11000 m3 de b√©ton bas carbone, le b√¢timent affiche un poids carbone in√©dit pour une \n",
            "construction tertiaire : 360 kgCO2e par m√®tre carr√©. R√©duire de 40 % les √©missions de GES : \n",
            "c‚Äôest l‚Äôune des obligations du chantier du Village des athl√®tes, √† Saint-Ouen (Seine-Saint-\n",
            "Denis). Pour ce faire, Eiffage Construction a exp√©riment√© l‚Äôutilisation d‚Äôisolants biosourc√©s √† \n",
            "grande √©chelle (10 000 m2). Des fa√ßades √† ossature bois ont √©t√© isol√©es avec de la laine de \n",
            "bois, choisie pour son coefficient de conductivit√© thermique. La filiale Goyer a r√©alis√© une \n",
            "fa√ßade en ossature bois pour un b√¢timent de huit √©tages qui accueillera des bureaux √† partir \n",
            "de 2025. B√©ton bas carbone Pour remplacer le clinker, principal constituant du ciment et \n",
            "√©l√©ment tr√®s carbon√©, Eiffage G√©nie Civil d√©veloppe des partenariats afin d‚Äôemployer des \n",
            "alternatives comme des laitiers d‚Äôaci√©ries. L‚Äôentreprise a aussi √©t√© laur√©ate d‚Äôun appel √† \n",
            "projets de la Soci√©t√© du Grand Paris (SGP) avec son innovation sur les voussoirs r√©alis√©s en \n",
            "b√©ton fibr√© bas carbone, qui √©conomise 10 000 tCO2e en moyenne pour 10 km de tunnel. Il \n",
            "sera notamment utilis√© sur une partie de la future ligne 16, dont le chantier a d√©but√© en \n",
            "septembre 2023. Le nouveau b√¢timent tertiaire du CHU de Rennes associe ossature en \n",
            "poteaux et poutres en bois lamell√© coll√©, planchers, et fa√ßades √† ossature bois. Bruno Astorg \n",
            "32_ Rapport climat Eiffage 2024 04 √âviter les √©missions pour nos clients Nov√© : lancement \n",
            "de la r√©novation du parc de logements du minist√®re des Arm√©es Nov√©, coentreprise qui \n",
            "r√©unit Eiffage et Arcade-VYV, a d√©but√© le 1er janvier 2023. Elle assure la gestion de la \n",
            "r√©novation du parc de logements du minist√®re des Arm√©es sur le territoire m√©tropolitain, \n",
            "apr√®s la signature du contrat de concession en 2022. Eiffage va exp√©rimenter la \n",
            "m√©thodologie R√©emploi en r√©novation du label bas carbone, qui vise √† g√©n√©rer des cr√©dits \n",
            "carbone certifi√©s. Cette m√©thodologie favorise le recours au r√©emploi et aux mat√©riaux \n",
            "biosourc√©s dans une op√©ration de r√©novation ou de r√©habilitation, en couvrant le surco√ªt par \n",
            "la vente des cr√©dits carbone g√©n√©r√©s. L‚Äôexp√©rimentation est financ√©e par Icade, en \n",
            "collaboration avec la Coop√©rative Carbone, le minist√®re de la Transition √©cologique et le \n",
            "Centre scientifique et technique du b√¢timent (CSTB). Calculettes carbone Afin de pouvoir \n",
            "proposer des variantes bas carbone dans les appels d‚Äôoffres, les m√©tiers se sont dot√©s de \n",
            "calculatrices carbone capables d‚Äôeffectuer deux calculs, l‚Äôun en euros, l‚Äôautre en √©missions \n",
            "de CO2. Elles √©valuent l‚Äôempreinte carbone des projets en prenant en compte divers \n",
            "√©l√©ments tels que les modes de transport ou les mat√©riaux utilis√©s. Dans les m√©tiers de la \n",
            "route, l‚Äôinterface num√©rique CARL, utilis√©e depuis 2021, a permis de montrer qu‚Äôen 2023 les \n",
            "√©missions de GES ont √©t√© r√©duites de 24 % dans les chantiers gagn√©s. La branche \n",
            "Infrastructures utilise sa propre calculatrice carbone, qui permet une prise en compte tr√®s \n",
            "r√©aliste des diff√©rents modes de fret et dont la m√©thodologie a √©t√© valid√©e par l‚ÄôAssociation \n",
            "pour la transition bas carbone (ABC) en 2023. La branche √ânergie Syst√®mes utilise Nooco, \n",
            "un outil particuli√®rement adapt√© aux m√©tiers du chauffage, de la ventilation et de la \n",
            "climatisation. La branche Construction a choisi la solution Logetex Carbone, qui proposera, \n",
            "dans un premier temps, des variantes pour le gros ≈ìuvre. ' metadata={'source': '../src/Conception et construction bas carbone.pdf', 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "# on utilise un loader (diff√©rent selon le type de fichier / le type de contenu √† analyser) pour charger les documents\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"../src/Conception et construction bas carbone.pdf\")\n",
        "data = loader.load()\n",
        "content=data[0]\n",
        "\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rwP1wmAlv9b"
      },
      "source": [
        "#2- Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2hV6zS3l3NX"
      },
      "source": [
        "Cette seconde √©tape consiste √† d√©couper le texte (nomm√©es \"chunk\") en petites parties de textes allant pouvoir √™tre vectoris√©es (trait√©es) et utilis√©es par un mod√®le d'IA (et notamment un LLM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e85mvKMbmHjO"
      },
      "outputs": [],
      "source": [
        "# il existe diff√©rentes strat√©gies de splitter. nous en utiliserons une appel√©e \"RecursuveCharacterTextSplitter\"\n",
        "# on d√©finit 2 param√®tres chunk_size pour la taille des chunks et l'overlap correspondant aux mots en commun entre 2 chunks\n",
        "\n",
        "from langchain.schema import Document\n",
        "\n",
        "chunk_size=1000\n",
        "chunk_overlap=200\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "rc_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\",\"\\n\",\" \",\"\"],\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap)\n",
        "\n",
        "chunks = rc_splitter.split_text(content.page_content)\n",
        "\n",
        "docs= [Document(page_content=chunk) for chunk in chunks] # note mme - besoin de convertir les chunks qui sont des string en docs avec page_content et meta donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78h30X7SuF_T",
        "outputId": "4f9c929c-a43b-48d9-c638-e6ed6c6f09bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de chunks : 6\n"
          ]
        }
      ],
      "source": [
        "print(f\"Nombre de chunks : {len(docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LCiDUq2n4i1"
      },
      "source": [
        "#3- Storage et retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0aI3Xb9n7xq"
      },
      "source": [
        "Cette troisi√®me √©tape consiste √† vectoriser les chunks pr√©c√©demment cr√©es et les stocker dans une base de donn√©es vectorielle. On utilise pour faire cela des embeddings (r√©seaux de neurones) et on d√©finit un retriever allant comparer selon une m√©thode donn√©e (dans notre cas nous utiliserons la similarit√©) les informations entrantes (input, la question) et la r√©ponse √† donner (output, issu de notre base documentaire)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F6DXnh9Noglb",
        "outputId": "91ee0d0b-ce9f-49da-e535-b43076aff8e7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_openai\n",
        "!pip install langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hsTZlq2FrasM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"from google.colab import userdata\\napi_key=userdata.get('OPENAI_API_KEY')\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# depuis collab \n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('OPENAI_API_KEY')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cl√© API r√©cup√©r√©e avec succ√®s !\n"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "# depuis visual code\n",
        "\"\"\" \n",
        "\n",
        "import os\n",
        "import openai\n",
        "\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if api_key:\n",
        "    print(\"Cl√© API r√©cup√©r√©e avec succ√®s !\")\n",
        "else:\n",
        "    print(\"Erreur : La cl√© API n'a pas √©t√© trouv√©e.\")\n",
        "\n",
        "from openai import OpenAI\n",
        "openai.api_key = api_key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDWdkOcIuZWL"
      },
      "source": [
        "### 3.1 - Initialisation de la base de donn√©es vectorielles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cLnPyF38mbfJ"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "embedding_function = OpenAIEmbeddings(api_key=api_key, model='text-embedding-3-small')\n",
        "\n",
        "vectorstore = Chroma.from_documents(docs,embedding=embedding_function, persist_directory=\"./chroma_db\") \n",
        "\n",
        "# cr√©ation d'un repertoire persitent pour le streamlit\n",
        "# Deprecated since version langchain-community==0.1.17: Since Chroma 0.4.x the manual persistence method is no longer supported as \n",
        "# # docs are automatically persisted.\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 2}\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDxPA-yvuh-r"
      },
      "source": [
        "### 3.2 - Construction d'un prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YgN6dTpZvDJ3",
        "outputId": "af126743-e9b1-40c2-ed20-4dc6ed9f3c6a"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QnKBHBRHum_7"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\"Tu es un assistant serviable. Consigne pour tes r√©ponses : {guidelines}\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"{copy}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aJYlCs338Lh",
        "outputId": "2a8125ae-6e88-4edb-d133-34532f128f2c"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=5, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dOgZ35I6yZ54"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\", api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SJkbSC-s4Jlg"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain #ConversationChain ne fonctionne pas avec un retriever - passer sur un RetrievalQA\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    memory=memory,\n",
        "    return_source_documents=False, # je n'arrive pas √† faire fonctionner les souces_documents\n",
        "    output_key=\"result\"  # n√©cessaire pour indiquer que l'on souhaite avoir uniquement ce r√©sultat en m√©moire -- beug sinon\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpfuY1NZzQsN"
      },
      "source": [
        "### 3.3 - Utilisation de la chaine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y186s921zVxz",
        "outputId": "60ddb1e9-5e85-412d-c257-03b2b59d400d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D'apr√®s les documents fournis, CARL est une interface num√©rique utilis√©e dans les m√©tiers de la route depuis 2021. Cependant, les documents ne fournissent pas plus de d√©tails sur les fonctionnalit√©s ou l'usage pr√©cis de cette interface.\n"
          ]
        }
      ],
      "source": [
        "# essai sans memoire avec chaine simple - √† ne pas relancer\n",
        "response = rag_chain.invoke(\"Qu'est ce que CARL ? \") # OK\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mdqa4Nu16i8",
        "outputId": "c53c5948-1b9a-4d13-c9a8-1f9ab1c75795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Je suis d√©sol√©, mais les documents fournis ne donnent pas d'informations pr√©cises sur ce qu'est Nooco. Il serait peut-√™tre utile de rechercher des informations suppl√©mentaires pour obtenir une r√©ponse pr√©cise √† cette question.\n"
          ]
        }
      ],
      "source": [
        "# essai sans memoire avec chaine simple - √† ne pas relancer\n",
        "response = rag_chain.invoke(\"Qu'est ce que  Nooco ? \") # NOK\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bogZrTc2j8M",
        "outputId": "84fa0df3-bf75-41a1-9ec1-e63af8f4a33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La branche Construction travaille avec la solution Logetex Carbone.\n"
          ]
        }
      ],
      "source": [
        "# essai sans memoire avec chaine simple - √† ne pas relancer\n",
        "response = rag_chain.invoke(\"Qui travaille avec Logetex Carbone ? \") # OK\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hokSFjya8VaW",
        "outputId": "55b67446-a8c3-4e9d-dc88-f76fb754215f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R√©sultat: Eiffage Construction a utilis√© des isolants biosourc√©s √† grande √©chelle sur le chantier du Village des athl√®tes. Plus pr√©cis√©ment, des fa√ßades √† ossature bois ont √©t√© isol√©es avec de la laine de bois.\n"
          ]
        }
      ],
      "source": [
        "# essai avec memoire avec RetrievalQA - √† lancer\n",
        "response = rag_chain({\"query\": \"Quel type d'isolant √† utiliser Eiffage sur le Village des Athl√®tes ??\"})\n",
        "result = response[\"result\"]\n",
        "\n",
        "print(\"R√©sultat:\", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHpszZHv4bAE",
        "outputId": "0469249a-15ec-4d64-8f2a-a2df82c382d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'Peux-tu rappeler ce que nous venons de dire ?', 'history': [HumanMessage(content=\"Quel type d'isolant √† utiliser Eiffage sur le Village des Athl√®tes ??\", additional_kwargs={}, response_metadata={}), AIMessage(content='Eiffage a utilis√© des isolants biosourc√©s pour le Village des athl√®tes, plus pr√©cis√©ment de la laine de bois.', additional_kwargs={}, response_metadata={})], 'result': \"Le rapport climat Eiffage 2024 mentionne plusieurs initiatives pour r√©duire les √©missions de carbone. Nov√©, une coentreprise entre Eiffage et Arcade-VYV, a commenc√© la r√©novation du parc de logements du minist√®re des Arm√©es en janvier 2023. Eiffage va exp√©rimenter la m√©thodologie R√©emploi en r√©novation du label bas carbone, qui favorise l'utilisation de mat√©riaux biosourc√©s et le r√©emploi dans les projets de r√©novation, et qui g√©n√®re des cr√©dits carbone. Cette exp√©rimentation est financ√©e par Icade, en collaboration avec la Coop√©rative Carbone, le minist√®re de la Transition √©cologique et le Centre scientifique et technique du b√¢timent (CSTB). \\n\\nEn outre, Eiffage Construction utilise du bois dans ses constructions, une solution de stockage carbone. Les solutions pr√©fabriqu√©es de Savare, une filiale sp√©cialis√©e dans la construction bois, sont utilis√©es dans plusieurs projets en cours. En 2023, Eiffage Construction a mis en place une action qui syst√©matise l'offre de variantes bas carbone dans les appels d‚Äôoffres sup√©rieurs √† 5 millions d‚Äôeuros.\"}\n"
          ]
        }
      ],
      "source": [
        "# essai avec memoire avec RetrievalQA - √† lancer -- v√©rification de la m√©moire\n",
        "response_2 = rag_chain({\"query\":\"Peux-tu rappeler ce que nous venons de dire ?\"})\n",
        "print(response_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR8DMuAO_frr"
      },
      "source": [
        "# 4 - Cr√©ation de l'interface"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Voir app.py pour l interface streamlit"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
